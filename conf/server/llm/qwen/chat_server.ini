[LLAMA3_CHAT_SERVER]
# port
port=8091
# host
host="localhost"
# max connection
max_connections=500
# peer resp timeout seconds
peer_resp_timeout=15
# request size limit(MB)
request_size_limit=-1
# compute threads nums
compute_threads=-1
# handler threads nums
handler_threads=50
# model worker nums
worker_nums=4
# milliseconds
model_run_timeout=-1
# server url
server_url="/mortred_ai_server_v1/qwen/qwen2.5/chat"

[LLAMA3_CHAT_MODEL]
model_config_file_path="../conf/model/llm/qwen/qwen-2.5-0.5B-instruct.ini"
