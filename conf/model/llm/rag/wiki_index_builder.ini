[WIKI_PREPROCESS]
llm_model_cfg_path="../conf/model/llm/llama/llama-3.2-3B-instruct.ini"
chunk_word_size=256
tokenize_max_seq_len=512
worker_nums=4
