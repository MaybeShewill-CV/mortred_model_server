[WIKI_PREPROCESS]
llm_model_cfg_path="../conf/model/llm/llama/llama-3.2-1B-instruct.ini"
chunk_word_size=256
tokenize_max_seq_len=512
segment_worker_nums=0
encode_worker_nums=0

[LLAMA3]
model_file_path="../weights/llm/llama/Llama-3.2-1B-Instruct/llama-3.2-1B-instruct-Q4_K_M.gguf"
n_gpu_layers=300
main_gpu_device=0
sampler_temp=0.7

[CONTEXT]
context_size=512